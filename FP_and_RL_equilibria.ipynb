{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d14f5fe7-5fed-47be-a6ea-967e5db5a29f",
   "metadata": {},
   "source": [
    "# Fictitious play and reinforcement learning for computing equilibria\n",
    "- Repeated & zero sum (stochastic) games\n",
    "- Fictitious play (FP) (theory and implementation)\n",
    "- Reinforcement Learning (RL) (theory and implementation)\n",
    "- Experimental results comparing FP and RL\n",
    "- Reinforcement Learning (RL) (theory and implementation) Experimental results comparing FP and RL\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Repeated & zero sum (stochastic) games\n",
    "\n",
    "### Zero-sum game\n",
    "**Situation**\n",
    "- competing entities\n",
    "- the result is an **advantage for one side** and an **equivalent loss** for the other (+5, -5)\n",
    "- the net improvement in benefit of the whole game is zero.\n",
    "    - Why? The advantage for one side is an equal loss for the other side.\n",
    "    - This sum is zero.\n",
    "\n",
    "#### Examples of games\n",
    "- poker\n",
    "- chess\n",
    "- sports?\n",
    "- bridge\n",
    "\n",
    "### Repeated/Iterated game\n",
    "- The same stage is played at each timeframe.\n",
    "- Repeated number of repetitions of a base game (stage game)\n",
    "- Same game, multiple games\n",
    "\n",
    "#### Examples\n",
    "- 2 gas stations offer competing prices\n",
    "- Stage Game: The single-shot game played in each period.\n",
    "\n",
    "### Stochastic/Markov games\n",
    "- dynamic, multi-agent\n",
    "- probabilities influence the transition to next state\n",
    "- player strategies depend only on the current state\n",
    "\n",
    "## Environment/Game description\n",
    "\n",
    "Construct a game/environment which combines the above 3 characteristics.\n",
    "In other words, it asks for a Competitive Markov Game, a two-player zero-sum game.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Equilibria\n",
    "\n",
    "### Nash equilibrium\n",
    "- no player could gain more by changing their play strategy in a game.\n",
    "- players choose their optimal strategy against the other players constant strategy\n",
    "- does not guarantee overall best pay-off\n",
    "- suboptimal for the group\n",
    "- **Pareto inefficient**\n",
    "\n",
    "\n",
    "### Pareto optimality/efficiency\n",
    "- is a group/collective strategy\n",
    "- every player is better off\n",
    "- no players in worse situations (aka no punished players)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Fictitious play - FP\n",
    "- players keep track of the empirical frequency of opponent's past moves\n",
    "    - i.e. player 2 played heads 60% of the time\n",
    "    - choose best response against that average\n",
    "- players adjust their strategies\n",
    "- players assume opponent's strategy based on past historical frequency\n",
    "- FP is guaranteed to converge to Nash equilibrium.\n",
    "    - WHY?\n",
    "    - Player 2, always chooses best/rational response against player 1's move\n",
    "- FP approach can be systematically exploited!!!\n",
    "\n",
    "**Refs**:\n",
    "What's FP:\n",
    "- https://en.wikipedia.org/wiki/Fictitious_play\n",
    "\n",
    "FP Agent design:\n",
    "- https://www.youtube.com/watch?v=_XIdEr-wtJg\n",
    "\n",
    "FP Agent beliefs initialization:\n",
    "- https://cse.unl.edu/~lksoh/Classes/CSCE475_875_Fall17/handouts/sup09.pdf\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Reinforcement Learning - RL\n",
    "- Player explores actions and receives rewards or punishments - feedback\n",
    "- Implemented via Q-learning or variants.\n",
    "- Q-value updated on trial and error - exploration\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Implementation\n",
    "\n",
    "### Environment 1. Simple Rock Paper Scissors - RPS\n",
    "\n",
    "- Same stage played at each iteration.\n",
    "\n",
    "### Environment 2. Beefy Rock-Paper-Scissors - BRPS\n",
    "\n",
    "This is a high stakes Rock-Paper-Scissors game.\n",
    "\n",
    "#### States\n",
    "1. `State-i`: Initial state: Standard rewards (+1 win, -1 loss)\n",
    "2. `State-n`: Next state: Rewards of previous state are doubled each time\n",
    "3. We cap the states to a number to reduce the amount of memory for the agents\n",
    "\n",
    "#### Stochastic transition (P)\n",
    "- If there's a draw at any state, there's a P-chance to transition into next state in which rewards double.\n",
    "- Otherwise, game stays in the same state.\n",
    "\n",
    "#### Zero-Sum rewards (R)\n",
    "- The sum of the rewards for Player 1 and Player 2 is always 0.\n",
    "- One player wins, other loses: rewards for one is equal penalty for other.\n",
    "\n",
    "#### Repeated\n",
    "- Player play 10 rounds of the same game.\n",
    "\n",
    "---\n",
    "\n",
    "# DONE\n",
    "\n",
    "- [x] imlement beefy RPS env\n",
    "- [x] implement FP agent\n",
    "- [x] implement q-learning agent\n",
    "- [x] Move into notebook\n",
    "- [x] implement **decaying** epsilon\n",
    "- [x] break into modules\n",
    "\n",
    "# TODO\n",
    "\n",
    "- [ ] **implement minmax q-learning** - https://github.com/tocom242242/minimax_q_learning\n",
    "\n",
    "- [ ] Convert into stochastic with limit cap\n",
    "- [ ] extract metrics [scores, env.state, q-table, sigma, epsilon, diagrams, experiments, interpretations, self-plays]\n",
    "- [ ] use petting zoo for RPS\n",
    "- [ ] research - competitive grid world\n",
    "- [ ] research - implement pong game (discrete actions)\n",
    "- [ ] research - hunter-pray game gridworld\n",
    "- [ ] research - implement multi-agent shooting game\n",
    "- [ ] implement SARSA agent - https://www.geeksforgeeks.org/machine-learning/sarsa-reinforcement-learning/\n",
    "- [ ] practical application ???\n",
    "- [ ] evolutionary algorithms - research\n",
    "- [ ] bomb difusal game/environment\n",
    "- [ ] penalties game/environment\n",
    "\n",
    "\n",
    "# Resources\n",
    "\n",
    "READ THIS FIRST: https://lefkippos.ds.unipi.gr/modules/document/file.php/AI_IIT113/Lectures%205%20%26%206%20Agents-Interactions_Game_Theory.pdf\n",
    "\n",
    "- Q-Learning (Pong) - https://courses.grainger.illinois.edu/ece448/sp2018/assignment4.html\n",
    "- evolutionary algo - https://www.cs.vu.nl/~gusz/ecbook/Eiben-Smith-Intro2EC-Ch2.pdf\n",
    "- evolutionary rl - https://github.com/RichardAragon/EvolutionaryReinforcementLearning\n",
    "- paper to get games, metrics, algos - https://github.com/shiivashaakeri/Pong-Deep-QLearning/blob/main/Report.pdf\n",
    "- q-learning tutorial - https://www.geeksforgeeks.org/machine-learning/q-learning-in-python/\n",
    "- book implementations for RL - https://github.com/ShangtongZhang/reinforcement-learning-an-introduction\n",
    "- RL taxonomy - https://github.com/bennylp/RL-Taxonomy\n",
    "- OpenAI RL taxonomy - https://spinningup.openai.com/en/latest/spinningup/rl_intro2.html\n",
    "- SARSA - https://github.com/linesd/tabular-methods/blob/master/algorithms/temporal_difference.py; https://www.geeksforgeeks.org/machine-learning/sarsa-reinforcement-learning/\n",
    "- ALL RL ALGOS - https://github.com/FareedKhan-dev/all-rl-algorithms/blob/master/cheatsheet.md\n",
    "- RL algorithms paper - https://arxiv.org/pdf/2209.14940\n",
    "- minmax q-learning - https://github.com/tocom242242/minimax_q_learning/blob/master/minimax_q_learner.py; https://github.com/theevann/MinimaxQ-Learning\n",
    "- Multi-Step Minimax Q-learning Algorithm for Two-Player Zero-Sum Markov Games - https://arxiv.org/abs/2407.04240\n",
    "- Policies in MDPS and games - https://courses.cs.duke.edu/spring07/cps296.3/littman94markov.pdf\n",
    "- **FLATLAND challenge** - https://gitlab.aicrowd.com/flatland/flatland; https://www.youtube.com/watch?v=cvkeWwDQr0A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b18cb80-924f-438b-83c6-68111ade10e3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6aad0f-3bc4-4430-a246-24520a2c1f89",
   "metadata": {},
   "source": [
    "# Environments\n",
    "\n",
    "## 1. Rock-Paper-Scissors - RPS\n",
    "\n",
    "To test the agents, we implement a simple Rock Paper Scissors - RPS environment. In each iteration, the agents play the same game - repeated.\n",
    "\n",
    "### States\n",
    "In its simple version, the same state is repeated in each iteration.\n",
    "\n",
    "In its stochastic version, the state has a transition probability into the next state. In the next state, the rewards are doubled.\n",
    "\n",
    "1. `State-i`: Initial state: Standard rewards (+1 win, -1 loss)\n",
    "2. `State-n`: Next state: Rewards of previous state are doubled each time\n",
    "3. We cap the states to a number to reduce the amount of memory for the agents\n",
    "\n",
    "### Stochastic transition (P)\n",
    "- If there's a draw at any state, there's a P-chance to transition into next state in which rewards double.\n",
    "- Otherwise, game stays in the same state.\n",
    "\n",
    "### Zero-Sum rewards (R)\n",
    "- The sum of the rewards for Player 1 and Player 2 is always 0.\n",
    "- One player wins, other loses: rewards for one is equal penalty for other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86135a70-58b4-4985-b993-3e5472d2853f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class RPS_environment():\n",
    "    \"\"\"\n",
    "    Rock Paper Scissors environment - simple.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, payoff_matrix=None, stochastic=False, transition_prob=0.3, max_states=3):\n",
    "\n",
    "        # Payoff Matrix: Player 1 rows, Player 2 cols\n",
    "        # 0: Rock\n",
    "        # 1: Paper\n",
    "        # 2: Scissors\n",
    "        # self.matrix = [\n",
    "        #         # R  P  S\n",
    "        #         [0, -1, 1],  # R\n",
    "        #         [1, 0, -1],  # P\n",
    "        #         [-1, 1, 0],  # S\n",
    "        #         ]\n",
    "        \n",
    "        self.payoff_matrix = payoff_matrix\n",
    "        self.stochastic = stochastic\n",
    "        self.state = 0\n",
    "        self.P = transition_prob\n",
    "        self.max_states = max_states\n",
    "        self.score1 = 0\n",
    "        self.score2 = 0\n",
    "        self.reward1 = 0\n",
    "        self.reward2 = 0\n",
    "        self.draws = 0\n",
    "\n",
    "    def step(self, action1, action2):\n",
    "        \"\"\"\n",
    "        Transition function:\n",
    "        1. receive actions from players\n",
    "        2. calculate rewards\n",
    "        3. update state\n",
    "        4. return information\n",
    "        \"\"\"\n",
    "\n",
    "        reward1 = self.payoff_matrix[action1][action2]*(self.state+1)\n",
    "        reward2 = -reward1\n",
    "\n",
    "        self.update_score(reward1, reward2)\n",
    "        self.update_reward(reward1, reward2)\n",
    "\n",
    "        # Calculate transition\n",
    "        if self.stochastic:\n",
    "            if action1 == action2:\n",
    "                if random.random() < self.P:\n",
    "                    if self.state < self.max_states:\n",
    "                        # We transition\n",
    "                        self.state += 1\n",
    "            else:\n",
    "                self.reset()\n",
    "\n",
    "        return self.state, reward1, reward2\n",
    "\n",
    "    def update_score(self, reward1, reward2):\n",
    "        \"\"\"Keep scores of the agents.\"\"\"\n",
    "        if reward1>reward2:\n",
    "            self.score1+=1\n",
    "        elif reward2>reward1:\n",
    "            self.score2+=1\n",
    "        else:\n",
    "            self.draws+=1\n",
    "\n",
    "    def update_reward(self, reward1, reward2):\n",
    "        \"\"\"Reward counter for each agent.\"\"\"\n",
    "        self.reward1 += reward1\n",
    "        self.reward2 += reward2\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Winning condition reached.\"\"\"\n",
    "        self.state = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fb69d2-95f1-4c5a-934c-d32ae5b43b57",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb753e1-343f-4872-a3d2-d5fa29c58e7c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Fictitious play - FP agent\n",
    "\n",
    "- This is a model based agent - tries to build a model of the environment to predict the best move.\n",
    "- It has a memory of the previous plays of the opponent - tracks state changes.\n",
    "- It tracks its opponents moves with a counter: `counts`\n",
    "- It tracks a distribution for each of the opponent's moves: `sigma`\n",
    "- In each round it plays the opposite move of the opponent: `best_move`\n",
    "- This agent can get trapped into playing non-optimal moves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "80962388-bc4d-412c-a783-db033cd3a077",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FictitiousPlayAgent():\n",
    "    \"\"\"\n",
    "    Fictitious Play Agent: A model based agent.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, payoff_matrix):\n",
    "        # Times a move has been played\n",
    "                      #R #P #S\n",
    "        self.counts = [1, 1, 1]\n",
    "\n",
    "        # Probability distribution\n",
    "                      #R #P #S\n",
    "        self.sigma = [0, 0, 0]\n",
    "\n",
    "        # Utility matrix\n",
    "        self.rows = 3\n",
    "        self.cols = 3\n",
    "        self.payoff_matrix = payoff_matrix\n",
    "\n",
    "    def action(self, opponent_action):\n",
    "        \"\"\"\n",
    "        Calculate the best action and ACT.\n",
    "        \"\"\"\n",
    "        if opponent_action is not None:\n",
    "            self.update_counts(opponent_action)\n",
    "            self.update_sigma(opponent_action)\n",
    "            best_move = self.find_best_move()\n",
    "        else:\n",
    "            best_move = random.randint(0, 2)\n",
    "        return best_move\n",
    "\n",
    "    def update_counts(self, opponent_action):\n",
    "        self.counts[opponent_action] += 1\n",
    "\n",
    "    def update_sigma(self, opponent_action):\n",
    "        for i in range(len(self.sigma)):\n",
    "            self.sigma[i] = round(self.counts[i]/sum(self.counts), 3)\n",
    "\n",
    "    def find_best_move(self):\n",
    "        \"\"\"\n",
    "        Calculates utilities using distribution sigma and returns best move.\n",
    "        \"\"\"\n",
    "        max_u = -float(\"inf\")\n",
    "        best_move = random.randint(0, 2)\n",
    "        for i in range(self.rows):\n",
    "            row_i_sum = sum([a*b for a, b in zip(self.payoff_matrix[i], self.sigma)])\n",
    "            if row_i_sum > max_u:\n",
    "                max_u = row_i_sum\n",
    "                best_move = i\n",
    "\n",
    "        return best_move"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab462b94-784d-494f-bcae-0a5e419097cc",
   "metadata": {},
   "source": [
    "## Q-learning agent - simple\n",
    "\n",
    "The simplest version of Q-learning algorithm.\n",
    "\n",
    "This agent keep a table for each of its actions. It dcides on the next action using Bellman's equation:\n",
    "\n",
    "Can get trapped and always select worst moves. Why? Because it does not take into account the opponent's move. In its worst case, all values in its `q_table` are all negative. This happens when during play, one of the action values drops bellow the threshold it can get increased by continuously getting a negative reward for its play. When that happens, this action will no longer be selected as the next action, unless it will be the maximum negative value. Even if it gets selected and played and the agent wins, the reward it will get, might not be enough to bring the value into positive state. In any case, the agent is trapped in playing the same move, the one with the greater value in its `q_table`. In other words, there's no guarantee it will converge to Nash equilibrium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "334a3b60-d9b8-42a5-8765-d5539352a3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class QLearning():\n",
    "    \"\"\"Generic Q-Learning algorightm.\"\"\"\n",
    "\n",
    "    def __init__(self, states=[0], actions=[0, 1, 2], epsilon_init=0.1):\n",
    "        # Initialize Q-table\n",
    "        self.q_table = {state: [0.0 for action in actions] for state in states}\n",
    "        self.epsilon = epsilon_init\n",
    "        self.alpha = 0.1\n",
    "        self.gamma = 0.9\n",
    "        self.action_space = actions\n",
    "\n",
    "    def action(self, state):\n",
    "        \"\"\"\n",
    "        Choose an action using the epsilon-greedy policy.\n",
    "        \"\"\"\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            # Explore\n",
    "            chosen_action = np.random.choice(self.action_space)\n",
    "        else:\n",
    "            # Exploit\n",
    "            state_values = self.q_table[state]\n",
    "            max_val = max(state_values)\n",
    "            # If we have multiple max values, choose one randomnly\n",
    "            best_action = [i for i, v in enumerate(state_values) if v == max_val]\n",
    "            chosen_action = np.random.choice(best_action)\n",
    "\n",
    "        return chosen_action\n",
    "        \n",
    "    def update_q_value(self, state, action, reward, next_state):\n",
    "        \"\"\"\n",
    "        Update the Q-value using Bellman eq..\n",
    "        \"\"\"\n",
    "        max_next_q = max(self.q_table[next_state])\n",
    "        # TEmpoeral difference\n",
    "        td_target = reward + self.gamma * max_next_q\n",
    "\n",
    "        # New Q value\n",
    "        self.q_table[state][action] += self.alpha * (td_target - self.q_table[state][action])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075cb8e5-da11-405b-9498-4b95375fed7e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Epsilon decay functions\n",
    "\n",
    "To prevent the Q-learning agent from getting stuck in playing the same move - one with highest values Q-table - we introduce the `epsilon_threshold` variable. This variable determines the eploration vs exploitation boundary. Here we implement several epsilon decay function to be used in RL algorithms which utilize Bellman's equation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79de3614-e484-4129-813a-f2a6134f0b18",
   "metadata": {},
   "source": [
    "### Linear epsilon decay\n",
    "\n",
    "In this scenario, `epsilon` decays by a stable step which is subtracted in each iteration. This allows for a smooth exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "5dc5795c-aa16-4063-a192-6348a7376992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Linear Epsilon Decay')"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Linear e\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "epsilon = 0.9\n",
    "step = 0.01\n",
    "data = []\n",
    "rounds = 100\n",
    "epsilon_threshold = 0.05 # Exploration limit\n",
    "\n",
    "for i in range(rounds):\n",
    "    if epsilon > epsilon_threshold:\n",
    "        epsilon -= step\n",
    "        data.append(round(epsilon, 3))\n",
    "    else:\n",
    "        data.append(data[-1])\n",
    "\n",
    "plt.plot(range(100), data)\n",
    "plt.xlabel(\"Rounds\")\n",
    "plt.ylabel(\"Epsilon\")\n",
    "plt.axhline(y=epsilon_threshold, color=\"orange\", linestyle=\"--\")\n",
    "plt.title(\"Linear Epsilon Decay\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16352a7a-1051-4ded-94cc-86bdeaae260c",
   "metadata": {},
   "source": [
    "### Exponential epsilon decay\n",
    "\n",
    "In this scenario, epsilon starts from a high value allowing the agent to explore, but then drops real quick transitioning in the exploitation phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "0693c3e2-1cb8-469c-a12c-25880e8b4a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Exponential Epsilon Decay')"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epsilon = 0.9\n",
    "decay_factor = 0.99\n",
    "data = []\n",
    "rounds = 1000\n",
    "epsilon_threshold = 0.05\n",
    "\n",
    "for i in range(rounds):\n",
    "    if epsilon > epsilon_threshold:\n",
    "        epsilon *= decay_factor\n",
    "        data.append(round(epsilon, 3))\n",
    "    else:\n",
    "        data.append(data[-1])\n",
    "\n",
    "plt.plot(range(rounds), data)\n",
    "plt.xlabel(\"Rounds\")\n",
    "plt.ylabel(\"Epsilon\")\n",
    "plt.axhline(y=epsilon_threshold, color=\"orange\", linestyle=\"--\")\n",
    "plt.title(\"Exponential Epsilon Decay\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a9ba30-b68b-4013-80f4-b0c7e559533f",
   "metadata": {},
   "source": [
    "## Q-learning agent - decaying epsilon\n",
    "\n",
    "This evolution of Q-learning agent uses the `epsilon_decay` variable, a value by which the exploration phase decays. Moreover, this implementation has an `epsilon_threshold` variable which prevents the agent from getting stuck in playing the same action from its `q_table` forcing it to play a random move instead. This technique, somewhat prevents the agent resulting in negative values in its `q_table`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84f936f7-f292-4011-a1a9-d004f4cf40bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class QLearning_decaying_epsilon():\n",
    "    \"\"\"\n",
    "    Generic Q-Learning algorightm.\n",
    "    INPUTS:\n",
    "      states<list> - numbered env states starting from 0\n",
    "      actions<list>- agent actions list starting from 0\n",
    "      epsilon_init<float> - initial epsilon value\n",
    "      epsilon_decay<float> - decay factor for epsilon value\n",
    "      epsilon_decay_strategy<string> - how epsilon factor should decay: [\"exp\",\"lin]\n",
    "      epsilon_threshold<float> - when should epsilon stop\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, states=[0], actions=[0, 1, 2], epsilon_init=0.9, epsilon_decay=0.949, epsilon_decay_strategy=\"exp\", epsilon_threshold=0.05):\n",
    "        # Initialize Q-table\n",
    "        self.q_table = {state: [0.0 for action in actions] for state in states}\n",
    "        self.epsilon = epsilon_init\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.epsilon_decay_strategy = epsilon_decay_strategy\n",
    "        self.epsilon_threshold = epsilon_threshold\n",
    "        self.alpha = 0.1\n",
    "        self.gamma = 0.9\n",
    "        self.action_space = actions\n",
    "\n",
    "    def action(self, state):\n",
    "        \"\"\"\n",
    "        Choose an action using the epsilon-greedy policy.\n",
    "        \"\"\"\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            # Explore\n",
    "            chosen_action = np.random.choice(self.action_space)\n",
    "        else:\n",
    "            # Exploit\n",
    "            state_values = self.q_table[state]\n",
    "            max_val = max(state_values)\n",
    "            # If we have multiple max values, choose one randomly\n",
    "            best_action = [i for i, v in enumerate(state_values) if v == max_val]\n",
    "            chosen_action = np.random.choice(best_action)\n",
    "\n",
    "        self.decay_epsilon()\n",
    "\n",
    "        return chosen_action\n",
    "\n",
    "    def decay_epsilon(self):\n",
    "        if self.epsilon > self.epsilon_threshold:\n",
    "            if self.epsilon_decay_strategy == \"exp\":\n",
    "                self.epsilon *= self.epsilon_decay\n",
    "            elif self.epsilon_decay_strategy == \"lin\":\n",
    "                self.epsilon -= self.epsilon_decay\n",
    "        \n",
    "    def update_q_value(self, state, action, reward, next_state):\n",
    "        \"\"\"\n",
    "        Update the Q-value using Bellman eq..\n",
    "        \"\"\"\n",
    "        max_next_q = max(self.q_table[next_state])\n",
    "        # TEmpoeral difference\n",
    "        td_target = reward + self.gamma * max_next_q\n",
    "\n",
    "        # New Q value\n",
    "        self.q_table[state][action] += self.alpha * (td_target - self.q_table[state][action])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e87bfa-a05e-4125-b58b-7195edb1b952",
   "metadata": {},
   "source": [
    "## Nash Q-Learning\n",
    "\n",
    "Extended Q-learning for adversarial multiagent environments. The algorithms assumes the opponent will always play rationally against it - will try to maximize its benefit. To counter that, it tracks moves and maintains a distribution `self.pi` over it's available actions. In each round, the logic solves a linear program which tries to **maximize the expected utility** `self.V`, but finding the values for the distribution `self.pi`.\n",
    "\n",
    "This system is either solved via the simplex method by converting the problem into typical form, or can be solved via 2-phase simplex by introducing slack variables `s_i` to convert constraints to equalities and artificial variables `a_i` which will need to be eliminated in phase-1. In phase-2, we should be left only with the original coefficients of the variables `self.pi` which determin the distribution over the actions.\n",
    "\n",
    "Ref: https://dl.acm.org/doi/pdf/10.5555/945365.964288\n",
    "\n",
    "Instead of tracking only `Q(state, action)`, this algorithm tracks `Q(state, action ,opponent_action)`. This allows it to learn what to do against an opponent's action for each state.\n",
    "\n",
    "The agent assumes the opponent will try to minimize its score. To counter, the agent tries to maximize that minimum possible score.\n",
    "\n",
    "In Rock Paper Scissors, we have a distribution over the moves: (e.g., 33% Rock, 33% Paper, 33% Scissors).\n",
    "\n",
    "### **Algorithm**\n",
    "\n",
    "1. **Initialize**: Q table for all combinations of states*actions*op_actions\n",
    "2. **Action**: Pick an action from the action space based on pi distribution\n",
    "3. **Observe**: What the opponent chose and what reward you got\n",
    "4. **Update**: Update the Q table for the pair of action,opp_action: `Q(a,o)=(1)Q(a,o)+(reward+Value)`\n",
    "\n",
    "Essentially, we solve a linear program using `linprog()` from `scipy`. What does this problem say:\n",
    "\n",
    "- Our `x` variables are the `pi` values which determine the action\n",
    "- Objective value is `V`\n",
    "- Coefficients of `x` are the `Q-table` values\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0469e30c-8d1a-4463-9679-561493c515e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimax Q-learning\n",
    "\n",
    "class Minimax_QLearning():\n",
    "    \"\"\"\n",
    "    Minimax Q-Learning.\n",
    "    INPUTS:\n",
    "      states<list> - numbered env states starting from 0\n",
    "      actions<list>- agent actions list starting from 0\n",
    "      epsilon_init<float> - initial epsilon value\n",
    "      epsilon_decay<float> - decay factor for epsilon value\n",
    "      epsilon_decay_strategy<string> - how epsilon factor should decay: [\"exp\",\"lin]\n",
    "      epsilon_threshold<float> - when should epsilon stop\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, states=[0], actions=[0, 1, 2], epsilon_init=0.9, epsilon_decay=0.949, epsilon_decay_strategy=\"exp\", epsilon_threshold=0.05, alpha=0.1, gamma=0.9):\n",
    "            # Q-table: state -> 2D matrix (our_actions x opp_actions)\n",
    "            self.q_table = {state: np.zeros((len(actions), len(actions))) for state in states}\n",
    "            \n",
    "            # Policy table: state -> probability distribution over actions\n",
    "            self.pi = {state: [1.0/len(actions) for _ in actions] for state in states}\n",
    "            \n",
    "            # State Value table: V(s)\n",
    "            self.V = {state: 0.0 for state in states}\n",
    "            \n",
    "            self.epsilon = epsilon_init\n",
    "            self.epsilon_decay = epsilon_decay\n",
    "            self.epsilon_decay_strategy = epsilon_decay_strategy\n",
    "            self.epsilon_threshold = epsilon_threshold\n",
    "            self.alpha = alpha\n",
    "            self.gamma = gamma\n",
    "            self.action_space = actions\n",
    "\n",
    "    def action(self, state):\n",
    "        \"\"\"\n",
    "        Choose an action using the epsilon-greedy policy.\n",
    "        \"\"\"\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            # Explore\n",
    "            chosen_action = np.random.choice(self.action_space)\n",
    "        else:\n",
    "            # Exploit - based on pi distribution\n",
    "            chosen_action = np.random.choice(self.action_space, p=self.pi[state])\n",
    "\n",
    "        self.decay_epsilon()\n",
    "        return chosen_action\n",
    "\n",
    "    def decay_epsilon(self):\n",
    "        if self.epsilon > self.epsilon_threshold:\n",
    "            if self.epsilon_decay_strategy == \"exp\":\n",
    "                self.epsilon *= self.epsilon_decay\n",
    "            elif self.epsilon_decay_strategy == \"lin\":\n",
    "                self.epsilon -= self.epsilon_decay\n",
    "\n",
    "    def observe(self, state, action, opp_action):\n",
    "        \"\"\"\n",
    "        Observe env.\n",
    "        opp_action - opponent's action\n",
    "        \"\"\"\n",
    "\n",
    "    def update_q_value(self, state, action, opp_action, reward, next_state):\n",
    "            \"\"\"\n",
    "            Update Q(s, a, o) and solve the Linear Program for the new policy pi(s).\n",
    "            \"\"\"\n",
    "            # 1. Update the specific Q-cell for the joint action\n",
    "            # Q(s, a, o) = (1-alpha) * Q(s, a, o) + alpha * (reward + gamma * V(s'))\n",
    "            # equivalent to Qnew=Qold+*(TargetQold)\n",
    "            target = reward + self.gamma * self.V[next_state]\n",
    "            self.q_table[state][action][opp_action] += self.alpha * (target - self.q_table[state][action][opp_action])\n",
    "    \n",
    "            # 2. Solve Linear Program to find the new V(s) and pi(s)\n",
    "            self.V[state], self.pi[state] = self._solve_minimax(state)\n",
    "\n",
    "    def _solve_minimax(self, state):\n",
    "        \"\"\"\n",
    "        Uses Scipy to find the Nash Equilibrium of the current Q-matrix at this state.\n",
    "        \"\"\"\n",
    "        Q = self.q_table[state]\n",
    "        num_actions = len(self.action_space)\n",
    "\n",
    "        # Objective function definition:\n",
    "        # linprog minimizes c^T * x. We want to maximize V, so we minimize -V.\n",
    "        # x vector: [p1, p2, p3, V]\n",
    "        # Essentially we pass: c = min(-V)\n",
    "        c = [0] * num_actions + [-1] # c = [0, 0, 0, -1] = coefficients of [piR, piP, piS, -V]\n",
    "        \n",
    "        # Build Inequality Constraints:\n",
    "        # sum(pi * Q_col) >= V  :=>  V - sum(pi * Q_col) <= 0\n",
    "        # We go down the row.\n",
    "        A_ub = []\n",
    "        for col in range(num_actions):\n",
    "            constraint = [-Q[row][col] for row in range(num_actions)] + [1]\n",
    "            A_ub.append(constraint)\n",
    "\n",
    "        # RHS here is zeros since we move V to the left, above\n",
    "        b_ub = [0] * num_actions\n",
    "        \n",
    "        # Build Equality Constraint:\n",
    "        # sum(pi) = 1 :=> pi1 + pi2 + pi3 + 0V = 1\n",
    "        A_eq = [[1] * num_actions + [0]]\n",
    "        # RHS of equality constraint is 1\n",
    "        b_eq = [1]\n",
    "\n",
    "        # Bounds: pi in [0, 1], V is unrestricted (None)\n",
    "        bounds = [(0, 1)] * num_actions + [(None, None)]\n",
    "\n",
    "        res = linprog(c, A_ub=A_ub, b_ub=b_ub, A_eq=A_eq, b_eq=b_eq, bounds=bounds, method=\"highs\")\n",
    "\n",
    "        if res.success:\n",
    "            new_pi = res.x[:num_actions] # new pi distribution values\n",
    "            # To ensure no precision errors lead to negative probabilities, we convert small numbers to zeroes\n",
    "            new_pi = np.maximum(new_pi, 0)\n",
    "            # Calculate new pi distribution values\n",
    "            new_pi /= np.sum(new_pi)\n",
    "            # Objective value\n",
    "            new_V = res.x[-1]\n",
    "            return new_V, new_pi\n",
    "        else:\n",
    "            return self.V[state], self.pi[state] # Fallback to old values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbde4f9-99b9-4f6a-a35a-843c27cee457",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85aea83d-fa00-4e02-affe-d1910aa75b8b",
   "metadata": {},
   "source": [
    "# Metrics\n",
    "\n",
    "\n",
    "## Regret\n",
    "To prove the performance of the agent, we track its regret in each round. In the RPS scenario, the regret for each agent is the opposite of its cummulative reward from each round:\n",
    "\n",
    "```python\n",
    "cum_reward1 += reward1\n",
    "cum_reward2 += reward2\n",
    "regret_history1.append(-cum_reward1)\n",
    "regret_history2.append(cum_reward2)\n",
    "```\n",
    "### Interpretation\n",
    "\n",
    "**Linear Growth**\n",
    "This is the worst case scenario, the agent kept loosing each round and its increased at a steady angle. The agent is making the same mistakes in each round and fails to learn the opponent's moves.\n",
    "\n",
    "**Flattened**\n",
    "Perhaps, the line goes up early, as the agent explores, but then flattens out. This means the agent has learned an optimal strategy, against its opponent, and is not exploiting it. It is no longer accumulating regret.\n",
    "\n",
    "**Negative slope**\n",
    "If regret goes down, the agent is actively exploiting its opponent's weakness. In each round the agent plays the optinal strategy against its opponent, thus we have Nash equilibrium."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ad1949-ac0e-414d-9a9b-e743761c05a3",
   "metadata": {},
   "source": [
    "# Scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf229d9-42e8-427f-beac-88ead2c3d18a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## FP self-play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "c19bfbea-9073-48ab-a64c-17f68cb81f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fp_self_play(rounds):\n",
    "    env = RPS_environment(\n",
    "        payoff_matrix=[\n",
    "                 # R  P  S\n",
    "                 [0, -1, 1],  # R\n",
    "                 [1, 0, -1],  # P\n",
    "                 [-1, 1, 0],  # S\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Row player\n",
    "    agent1 = FictitiousPlayAgent(\n",
    "            [\n",
    "                 #R  P  S\n",
    "                [0, -1, 1],  # R\n",
    "                [1, 0, -1],  # P\n",
    "                [-1, 1, 0],  # S\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    # Column player\n",
    "    agent2 = FictitiousPlayAgent(\n",
    "            [\n",
    "                #R  P  S\n",
    "                [0, 1, -1],  # R\n",
    "                [-1, 0, 1],  # P\n",
    "                [1, -1, 0],  # S\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    # Initializer\n",
    "    last_act2 = None\n",
    "    last_act1 = None\n",
    "\n",
    "    env.reset()\n",
    "\n",
    "    for i in range(rounds):\n",
    "        curr_act1 = agent1.action(last_act2)\n",
    "        curr_act2 = agent2.action(last_act1)\n",
    "\n",
    "        env.step(curr_act1, curr_act2)\n",
    "\n",
    "        last_act1 = curr_act1\n",
    "        last_act2 = curr_act2\n",
    "\n",
    "    print(f\"Agent 1\\ncounts: {agent1.counts}\\nsigma: {agent1.sigma}\\nScore: {env.score1}\\nTotal reward: {env.reward1}\")\n",
    "    print(\"----------------\")\n",
    "    print(f\"Agent 2\\ncounts: {agent2.counts}\\nsigma: {agent2.sigma}\\nScore: {env.score2}\\nTotal reward: {env.reward2}\")\n",
    "    print(f\"Draws: {env.draws}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "282167c3-e5e8-47b4-bad5-471d870520aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent 1\n",
      "counts: [1, 34, 67]\n",
      "sigma: [0.01, 0.333, 0.657]\n",
      "Score: 0\n",
      "Total reward: -34\n",
      "----------------\n",
      "Agent 2\n",
      "counts: [34, 1, 67]\n",
      "sigma: [0.333, 0.01, 0.657]\n",
      "Score: 34\n",
      "Total reward: 34\n",
      "Draws: 66\n"
     ]
    }
   ],
   "source": [
    "fp_self_play(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8553e84b-a351-428a-a716-e79d14fd90fb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## FP vs Q-learning simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "706cc878-1eaa-4389-9005-c4746807961c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fp_vs_qlearning(rounds):\n",
    "    \n",
    "    env = RPS_environment(\n",
    "        payoff_matrix=[\n",
    "                 # R  P  S\n",
    "                 [0, -1, 1],  # R\n",
    "                 [1, 0, -1],  # P\n",
    "                 [-1, 1, 0],  # S\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Row agent\n",
    "    agent1 = FictitiousPlayAgent(\n",
    "            [\n",
    "                 #R  P  S\n",
    "                [0, -1, 1],  # R\n",
    "                [1, 0, -1],  # P\n",
    "                [-1, 1, 0],  # S\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    agent2 = QLearning(epsilon_init=0.4)\n",
    "\n",
    "    # Initializer\n",
    "    last_act2 = None\n",
    "\n",
    "    env.reset()\n",
    "\n",
    "    for i in range(rounds):\n",
    "        curr_env_state = env.state\n",
    "\n",
    "        # Register actions\n",
    "        curr_act1 = agent1.action(last_act2)\n",
    "        curr_act2 = agent2.action(curr_env_state) # pass curr env state\n",
    "\n",
    "        # Step the environment\n",
    "        next_env_state, reward1, reward2 = env.step(curr_act1, curr_act2)\n",
    "\n",
    "        # RL agent learns\n",
    "        agent2.update_q_value(curr_env_state, curr_act2, reward2, next_env_state)\n",
    "\n",
    "        last_act2 = curr_act2\n",
    "\n",
    "    print(f\"FP\\ncounts: {agent1.counts}\\nsigma: {agent1.sigma}\\nScore: {env.score1}\\nTotal reward: {env.reward1}\")\n",
    "    print(\"------------\")\n",
    "    print(f\"Q-learning\\nq_table: {agent2.q_table}\\nScore: {env.score2}\\nTotal reward: {env.reward2}\")\n",
    "    print(f\"Draws: {env.draws}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "a7a06c04-ca0d-440a-99af-7781ea7e057e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP\n",
      "counts: [37, 34, 31]\n",
      "sigma: [0.363, 0.333, 0.304]\n",
      "Score: 30\n",
      "Total reward: -10\n",
      "------------\n",
      "Q-learning\n",
      "q_table: {0: [0.4737487042586635, 0.2854262870400299, 0.8060943997284843]}\n",
      "Score: 40\n",
      "Total reward: 10\n",
      "Draws: 30\n"
     ]
    }
   ],
   "source": [
    "fp_vs_qlearning(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8dc3cd9-a35b-4de6-b4c8-d5f1df593eec",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## FP vs Q-learning decaying epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1c22ced-6e50-43c7-97b3-eb8feeb01da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fp_vs_qlearning_decaying_epsilon(rounds):\n",
    "    \n",
    "    env = RPS_environment(\n",
    "        payoff_matrix=[\n",
    "                 # R  P  S\n",
    "                 [0, -1, 1],  # R\n",
    "                 [1, 0, -1],  # P\n",
    "                 [-1, 1, 0],  # S\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Row agent\n",
    "    agent1 = FictitiousPlayAgent(\n",
    "            [\n",
    "                 #R  P  S\n",
    "                [0, -1, 1],  # R\n",
    "                [1, 0, -1],  # P\n",
    "                [-1, 1, 0],  # S\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    agent2 = QLearning_decaying_epsilon(epsilon_init=0.9, epsilon_decay=0.99, epsilon_decay_strategy=\"exp\", epsilon_threshold=0.1)\n",
    "\n",
    "    # Initializer\n",
    "    last_act2 = None\n",
    "\n",
    "    env.reset()\n",
    "\n",
    "    for i in range(rounds):\n",
    "        curr_env_state = env.state\n",
    "\n",
    "        # Register actions\n",
    "        curr_act1 = agent1.action(last_act2)\n",
    "        curr_act2 = agent2.action(curr_env_state) # pass curr env state\n",
    "\n",
    "        # Step the environment\n",
    "        next_env_state, reward1, reward2 = env.step(curr_act1, curr_act2)\n",
    "\n",
    "        # RL agent learns\n",
    "        agent2.update_q_value(curr_env_state, curr_act2, reward2, next_env_state)\n",
    "\n",
    "        last_act2 = curr_act2\n",
    "\n",
    "    print(f\"FP\\ncounts: {agent1.counts}\\nsigma: {agent1.sigma}\\nScore: {env.score1}\\nTotal reward: {env.reward1}\")\n",
    "    print(\"------------\")\n",
    "    print(f\"Q-learning\\nq_table: {agent2.q_table}\\nScore: {env.score2}\\nTotal reward: {env.reward2}\")\n",
    "    print(f\"Draws: {env.draws}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "543150d0-e528-45c3-9490-ca08748fc22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP\n",
      "counts: [330, 328, 344]\n",
      "sigma: [0.329, 0.327, 0.343]\n",
      "Score: 247\n",
      "Total reward: -31\n",
      "------------\n",
      "Q-learning\n",
      "q_table: {0: [0.3180103178061194, 0.046365463948615855, 0.2918325401259797]}\n",
      "Score: 278\n",
      "Total reward: 31\n",
      "Draws: 475\n"
     ]
    }
   ],
   "source": [
    "fp_vs_qlearning_decaying_epsilon(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88f12b9-7bc6-44f3-b5c6-74c09db34bef",
   "metadata": {},
   "source": [
    "## Q-learning decaying epsilon vs Nash Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f57a24ec-409b-4ffd-b7a9-a9b3124c8004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import linprog\n",
    "\n",
    "def qlearning_vs_minimax_q(rounds):\n",
    "\n",
    "    # Init metrics\n",
    "    regret_history_agent1 = []\n",
    "    regret_history_agent2 = []\n",
    "    cum_reward1 = 0\n",
    "    cum_reward2 = 0\n",
    "    \n",
    "    # Setup environment\n",
    "    env = RPS_environment(\n",
    "        payoff_matrix=[\n",
    "            [0, -1, 1],  # R\n",
    "            [1, 0, -1],  # P\n",
    "            [-1, 1, 0],  # S\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Agent 1: Minimax-Q (Nash) - Row Player\n",
    "    agent1 = Minimax_QLearning(epsilon_init=0.9, epsilon_decay=0.99, epsilon_decay_strategy=\"exp\", epsilon_threshold=0.1)\n",
    "\n",
    "    # Agent 2: Standard Q-Learning - Column Player\n",
    "    agent2 = QLearning_decaying_epsilon(epsilon_init=0.9, epsilon_decay=0.99, epsilon_decay_strategy=\"exp\", epsilon_threshold=0.1)\n",
    "\n",
    "    env.reset()\n",
    "\n",
    "    for i in range(rounds):\n",
    "        curr_state = env.state\n",
    "\n",
    "        # 1. Get Actions\n",
    "        act1 = agent1.action(curr_state)\n",
    "        act2 = agent2.action(curr_state)\n",
    "\n",
    "        # 2. Step Environment\n",
    "        next_state, r1, r2 = env.step(act1, act2)\n",
    "\n",
    "        # 2.5 Update metrics\n",
    "        cum_reward1 += r1\n",
    "        cum_reward2 += r2\n",
    "        regret_history_agent1.append(-cum_reward1)\n",
    "        regret_history_agent2.append(-cum_reward2)\n",
    "\n",
    "        # 3. Update Minimax-Q (Requires BOTH actions)\n",
    "        agent1.update_q_value(curr_state, act1, act2, r1, next_state)\n",
    "\n",
    "        # 4. Update Standard Q-Learning (Only requires its own action)\n",
    "        agent2.update_q_value(curr_state, act2, r2, next_state)\n",
    "\n",
    "    # Final Reporting\n",
    "    print(f\"Minimax-Q (Nash)\\nScore: {env.score1}\\nTotal reward: {env.reward1}\")\n",
    "    print(f\"V(s=0): {agent1.V[0]:.4f}\")\n",
    "    print(f\"Policy(s=0): {np.round(agent1.pi[0], 3)}\")\n",
    "    print(\"------------\")\n",
    "    print(f\"Standard Q-learning\\nScore: {env.score2}\\nTotal reward: {env.reward2}\")\n",
    "    print(f\"Q-table(s=0): {np.round(agent2.q_table[0], 3)}\")\n",
    "    print(\"------------\")\n",
    "    print(f\"Draws: {env.draws}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6d05062c-811d-475d-9df8-e23f32c37e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimax-Q (Nash)\n",
      "Score: 32\n",
      "Total reward: -7\n",
      "V(s=0): -0.0183\n",
      "Policy(s=0): [0.343 0.299 0.358]\n",
      "------------\n",
      "Standard Q-learning\n",
      "Score: 39\n",
      "Total reward: 7\n",
      "Q-table(s=0): [0.302 0.3   0.47 ]\n",
      "------------\n",
      "Draws: 29\n"
     ]
    }
   ],
   "source": [
    "qlearning_vs_minimax_q(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0a28ae-6046-4d27-bb62-0944c307ac2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
